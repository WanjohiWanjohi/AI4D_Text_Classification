{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1+iVqykAvBLzk6LdMFaUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WanjohiWanjohi/AI4D_Text_Classification/blob/main/AI4D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyQu1GWS4jRE"
      },
      "source": [
        "A notebook for thee exploration and analysis of the NLP Zindi challenge that can be found at [AI4D Malawi competion](https://zindi.africa/competitions/ai4d-malawi-news-classification-challenge/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsBbZtk74H_c"
      },
      "source": [
        "#import necessary libraries\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np \r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Rd3NQ96xGM"
      },
      "source": [
        "train_df = pd.read_csv('Train.csv')\r\n",
        "test_df = pd.read_csv('Test.csv')\r\n",
        "sampl_submission_df = pd.read_csv('SampleSubmission.csv')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdhaLUDOwKyx"
      },
      "source": [
        "Vectorize the Text column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RojnVrtCwNf8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65cWs0K38utL"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "\r\n",
        "# Transform each text into a vector of word counts\r\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2))\r\n",
        "\r\n",
        "training_features = vectorizer.fit_transform(train_df[\"Text\"])    \r\n",
        "test_features = vectorizer.transform(test_df[\"Text\"])\r\n",
        "\r\n",
        "# Training\r\n",
        "model = LinearSVC(max_iter=5000)\r\n",
        "model.fit(training_features, train_df[\"Label\"])\r\n",
        "y_pred = model.predict(test_features)\r\n",
        "\r\n",
        "# Evaluation\r\n",
        "# acc = accuracy_score(train_df[\"Label\"], y_pred)\r\n",
        "\r\n",
        "# print(\"Accuracy on the IMDB dataset: {:.2f}\".format(acc*100))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TteQ8qMmFqf_"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nta51N33HH7n"
      },
      "source": [
        "sampl_submission_df['Label'] = y_pred"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1StFqAZGucj",
        "outputId": "3554376d-5187-4ffc-c1b4-f77638c11e37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "sampl_submission_df"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_ADHEtjTi</td>\n",
              "      <td>SOCIAL ISSUES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_AHfJktdQ</td>\n",
              "      <td>RELIGION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_AUJIHpZr</td>\n",
              "      <td>RELATIONSHIPS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_AUKYBbIM</td>\n",
              "      <td>POLITICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_AZnsVPEi</td>\n",
              "      <td>HEALTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>ID_zdpOUWyJ</td>\n",
              "      <td>LAW/ORDER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>ID_zhnOomuu</td>\n",
              "      <td>RELATIONSHIPS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>ID_zmWHvBJb</td>\n",
              "      <td>LAW/ORDER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>ID_zphjdFIb</td>\n",
              "      <td>SOCIAL ISSUES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619</th>\n",
              "      <td>ID_ztdtrNxt</td>\n",
              "      <td>POLITICS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>620 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID          Label\n",
              "0    ID_ADHEtjTi  SOCIAL ISSUES\n",
              "1    ID_AHfJktdQ       RELIGION\n",
              "2    ID_AUJIHpZr  RELATIONSHIPS\n",
              "3    ID_AUKYBbIM       POLITICS\n",
              "4    ID_AZnsVPEi         HEALTH\n",
              "..           ...            ...\n",
              "615  ID_zdpOUWyJ      LAW/ORDER\n",
              "616  ID_zhnOomuu  RELATIONSHIPS\n",
              "617  ID_zmWHvBJb      LAW/ORDER\n",
              "618  ID_zphjdFIb  SOCIAL ISSUES\n",
              "619  ID_ztdtrNxt       POLITICS\n",
              "\n",
              "[620 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDPeHAgY-ScC"
      },
      "source": [
        "sampl_submission_df.to_csv('submission_LinearSVC4' , index=False )"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krtjtlQQKP6M"
      },
      "source": [
        "This model as is gives an accuracy of 60% , which is just slightly better than guesswork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkv1VaCNE428"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GYyz0nJFBk",
        "outputId": "bd06ff35-4324-4568-a36b-1b0bf901b0db"
      },
      "source": [
        "!pip install skipthoughts\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skipthoughts\n",
            "  Downloading https://files.pythonhosted.org/packages/34/10/e0b1f148f19b2a792f3811822feeb7f5561de5ae2fffe9b9544642447cdc/skipthoughts-0.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from skipthoughts) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from skipthoughts) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->skipthoughts) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->skipthoughts) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->skipthoughts) (0.8)\n",
            "Installing collected packages: skipthoughts\n",
            "Successfully installed skipthoughts-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FLOeFwI3F0"
      },
      "source": [
        "#implement a vectorizer\r\n",
        "import skipthoughts\r\n",
        "\r\n",
        "class SkipThoughtsVectorizer(object):\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        self.model = skipthoughts.load_model()\r\n",
        "        self.encoder = skipthoughts.Encoder(self.model)\r\n",
        "\r\n",
        "    def fit_transform(self, raw_documents, y):\r\n",
        "        return self.encoder.encode(raw_documents, verbose=False)\r\n",
        "\r\n",
        "    def fit(self, raw_documents, y=None):\r\n",
        "        self.fit_transform(raw_documents, y)\r\n",
        "        return self\r\n",
        "\r\n",
        "    def transform(self, raw_documents, copy=True):\r\n",
        "        return self.fit_transform(raw_documents, None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD-syf8HJv_5"
      },
      "source": [
        "Now we will define three scikit-learn pipelines.\r\n",
        "\r\n",
        " One that uses our SkipThoughtsVectorizer, \r\n",
        " One that uses the TF-IDF bag of n-grams approach\r\n",
        " One  that uses a combination of both. \r\n",
        " In the three of them, we will use a simple Logistic Regression model for classifying our data.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "pA04jBU8Jusn",
        "outputId": "ba5df1f9-cb0d-4a1b-8372-e85f1db64fbc"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "SkipThoughtsVectorizer()\r\n",
        "pipeline_skipthought = Pipeline(steps=[('vectorizer', SkipThoughtsVectorizer()),\r\n",
        "                        ('classifier', LogisticRegression())])\r\n",
        "\r\n",
        "pipeline_tfidf = Pipeline(steps=[('vectorizer', TfidfVectorizer(ngram_range=(1, 2))),\r\n",
        "                        ('classifier', LogisticRegression())])\r\n",
        "\r\n",
        "feature_union = ('feature_union', FeatureUnion([\r\n",
        "    ('skipthought', SkipThoughtsVectorizer()),\r\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\r\n",
        "]))\r\n",
        "pipeline_both = Pipeline(steps=[feature_union,\r\n",
        "                        ('classifier', LogisticRegression())])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-127a91f53511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSkipThoughtsVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m pipeline_skipthought = Pipeline(steps=[('vectorizer', SkipThoughtsVectorizer()),\n\u001b[1;32m      6\u001b[0m                         ('classifier', LogisticRegression())])\n",
            "\u001b[0;32m<ipython-input-7-d36ad3bc0531>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSkipThoughtsVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipthoughts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipthoughts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'skipthoughts' has no attribute 'load_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-2agO7iLH96"
      },
      "source": [
        "skipthoughts ?\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}